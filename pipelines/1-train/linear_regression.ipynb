{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f91d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, size, length, when, log1p, expm1, lower, percentile_approx, count\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Price Prediction LR\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "DATA_PATH = \"../../data/regression_price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ddc0902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 699283\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(DATA_PATH)\n",
    "print(f\"Total rows: {df.count()}\")\n",
    "\n",
    "has_array_features = [f.dataType for f in df.schema.fields if f.name == \"features\"]\n",
    "if str(has_array_features[0]).startswith(\"ArrayType\"):\n",
    "    df = df.withColumn(\"features_count\", size(col(\"features\")))\n",
    "else:\n",
    "    if \"features_count\" not in df.columns and \"features\" in df.columns:\n",
    "         df = df.withColumn(\"features_count\", length(col(\"features\")))\n",
    "\n",
    "required_cols = [\"rating_number\", \"average_rating\", \"main_category\", \"price\"]\n",
    "df_clean = df.dropna(subset=required_cols)\n",
    "\n",
    "store_counts = df_clean.groupBy(\"store\").agg(count(\"*\").alias(\"store_freq\"))\n",
    "df_improved = df_clean.join(store_counts, on=\"store\", how=\"left\")\n",
    "df_improved = df_improved.na.fill(0, subset=[\"store_freq\", \"features_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68c850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Bounds: 1.00 - 105.49\n",
      "Rows for training: 565678\n"
     ]
    }
   ],
   "source": [
    "price_stats = df_improved.select(\n",
    "    percentile_approx(\"price\", 0.25).alias(\"q1\"),\n",
    "    percentile_approx(\"price\", 0.75).alias(\"q3\")\n",
    ").collect()[0]\n",
    "\n",
    "q1, q3 = price_stats[\"q1\"], price_stats[\"q3\"]\n",
    "iqr = q3 - q1\n",
    "lower_bound = max(1.0, q1 - 1.5 * iqr)  \n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "print(f\"Price Bounds: {lower_bound:.2f} - {upper_bound:.2f}\")\n",
    "\n",
    "df_featured = df_improved.filter(\n",
    "    (col(\"price\") >= lower_bound) & (col(\"price\") <= upper_bound)\n",
    ")\n",
    "\n",
    "if \"title\" in df_featured.columns:\n",
    "    df_featured = df_featured.withColumn(\"title_len\", length(col(\"title\")))\n",
    "    df_featured = df_featured.withColumn(\"is_premium\", when(lower(col(\"title\")).rlike(\"premium|pro|deluxe\"), 1).otherwise(0))\n",
    "    df_featured = df_featured.withColumn(\"is_bundle\", when(lower(col(\"title\")).rlike(\"bundle|set|pack\"), 1).otherwise(0))\n",
    "\n",
    "df_featured = df_featured.withColumn(\"log_rating_number\", log1p(col(\"rating_number\")))\n",
    "df_featured = df_featured.withColumn(\"log_store_freq\", log1p(col(\"store_freq\")))\n",
    "\n",
    "df_featured = df_featured.withColumn(\"label\", log1p(col(\"price\")))\n",
    "\n",
    "print(f\"Rows for training: {df_featured.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6e520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    Tokenizer, HashingTF, StringIndexer, \n",
    "    OneHotEncoder, VectorAssembler, StandardScaler\n",
    ")\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "stages = []\n",
    "\n",
    "if \"title\" in df_featured.columns:\n",
    "    tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"words\")\n",
    "    stages.append(tokenizer)\n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"title_features\", numFeatures=300)\n",
    "    stages.append(hashingTF)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"main_category\", outputCol=\"category_idx\", handleInvalid=\"keep\")\n",
    "stages.append(indexer)\n",
    "encoder = OneHotEncoder(inputCol=\"category_idx\", outputCol=\"category_vec\")\n",
    "stages.append(encoder)\n",
    "\n",
    "numeric_cols = [\"average_rating\", \"log_rating_number\", \"log_store_freq\"]\n",
    "optional_cols = [\"title_len\", \"is_premium\", \"is_bundle\", \"features_count\"]\n",
    "\n",
    "for c in optional_cols:\n",
    "    if c in df_featured.columns:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "input_cols = numeric_cols + [\"category_vec\"]\n",
    "if \"title\" in df_featured.columns:\n",
    "    input_cols.append(\"title_features\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features_raw\")\n",
    "stages.append(assembler)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features_vector\", withStd=True, withMean=False)\n",
    "stages.append(scaler)\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features_vector\", \n",
    "    labelCol=\"label\",\n",
    "    maxIter=50,\n",
    "    regParam=0.1,\n",
    "    elasticNetParam=0.5\n",
    ")\n",
    "stages.append(lr)\n",
    "\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ee5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression model...\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df_featured.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Training Linear Regression model...\")\n",
    "model = pipeline.fit(train_data)\n",
    "print(\"Training Complete!\")\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "predictions = predictions.withColumn(\"prediction_price\", expm1(col(\"prediction\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c238eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "  R2 (Log Scale): 0.0539\n",
      "  RMSE (Real $):  22.82\n",
      "  MAE (Real $):   15.49\n",
      "\n",
      "Example Predictions:\n",
      "+---------------------------------------------+-----+------------------+\n",
      "|title                                        |price|prediction_price  |\n",
      "+---------------------------------------------+-----+------------------+\n",
      "|Warhammer 40k Adeptus Mechanicus Codex       |22.41|22.089285612794676|\n",
      "|IA N64 Mem Asst.                             |10.49|22.089285612794676|\n",
      "|Beetle Adventure Racing                      |43.98|22.089285612794676|\n",
      "|Scubapro Quick Release Mouthpiece Clamp      |14.95|22.089285612794676|\n",
      "|Replacement Lens (Screen) for Game Boy Pocket|12.94|22.089285612794676|\n",
      "+---------------------------------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "r2_eval = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rmse_eval = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction_price\", metricName=\"rmse\")\n",
    "mae_eval = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction_price\", metricName=\"mae\")\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "print(f\"  R2 (Log Scale): {r2_eval.evaluate(predictions):.4f}\")\n",
    "print(f\"  RMSE (Real $):  {rmse_eval.evaluate(predictions):.2f}\")\n",
    "print(f\"  MAE (Real $):   {mae_eval.evaluate(predictions):.2f}\")\n",
    "\n",
    "print(\"\\nExample Predictions:\")\n",
    "predictions.select(\"title\", \"price\", \"prediction_price\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a0a479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept (Базова логарифмічна ціна): 3.1394\n",
      "\n",
      "Approximate Coefficients for Numeric Features:\n",
      "  average_rating: 0.0000\n",
      "  log_rating_number: 0.0000\n",
      "  log_store_freq: 0.0000\n",
      "  title_len: 0.0000\n",
      "  is_premium: 0.0000\n",
      "  is_bundle: 0.0000\n",
      "  features_count: 0.0000\n"
     ]
    }
   ],
   "source": [
    "lr_model = model.stages[-1]\n",
    "\n",
    "print(f\"Intercept (Базова логарифмічна ціна): {lr_model.intercept:.4f}\")\n",
    "\n",
    "print(\"\\nApproximate Coefficients for Numeric Features:\")\n",
    "coeffs = lr_model.coefficients\n",
    "for i, name in enumerate(numeric_cols):\n",
    "    if i < len(coeffs):\n",
    "        print(f\"  {name}: {coeffs[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b7273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../../models/regression/lr_price_log_v1\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../../models/regression/lr_price_log_v1\"\n",
    "model.write().overwrite().save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21132fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
