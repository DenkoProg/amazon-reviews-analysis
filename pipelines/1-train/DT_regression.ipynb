{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d34a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, size, length, when, log1p, expm1, lower, percentile_approx, count\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Price Prediction DT\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "DATA_PATH = \"../../data/regression_price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffa8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(DATA_PATH)\n",
    "\n",
    "has_array_features = [f.dataType for f in df.schema.fields if f.name == \"features\"]\n",
    "if str(has_array_features[0]).startswith(\"ArrayType\"):\n",
    "    df = df.withColumn(\"features_count\", size(col(\"features\")))\n",
    "else:\n",
    "    if \"features_count\" not in df.columns and \"features\" in df.columns:\n",
    "         df = df.withColumn(\"features_count\", length(col(\"features\")))\n",
    "\n",
    "required_cols = [\"rating_number\", \"average_rating\", \"main_category\", \"price\"]\n",
    "df_clean = df.dropna(subset=required_cols)\n",
    "\n",
    "store_counts = df_clean.groupBy(\"store\").agg(count(\"*\").alias(\"store_freq\"))\n",
    "df_improved = df_clean.join(store_counts, on=\"store\", how=\"left\")\n",
    "df_improved = df_improved.na.fill(0, subset=[\"store_freq\", \"features_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5bb970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for Decision Tree: 565678 rows\n"
     ]
    }
   ],
   "source": [
    "price_stats = df_improved.select(\n",
    "    percentile_approx(\"price\", 0.25).alias(\"q1\"),\n",
    "    percentile_approx(\"price\", 0.75).alias(\"q3\")\n",
    ").collect()[0]\n",
    "\n",
    "q1, q3 = price_stats[\"q1\"], price_stats[\"q3\"]\n",
    "iqr = q3 - q1\n",
    "lower_bound = max(1.0, q1 - 1.5 * iqr)\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "df_featured = df_improved.filter(\n",
    "    (col(\"price\") >= lower_bound) & (col(\"price\") <= upper_bound)\n",
    ")\n",
    "\n",
    "if \"title\" in df_featured.columns:\n",
    "    df_featured = df_featured.withColumn(\"title_len\", length(col(\"title\")))\n",
    "    df_featured = df_featured.withColumn(\"is_premium\", when(lower(col(\"title\")).rlike(\"premium|pro|deluxe\"), 1).otherwise(0))\n",
    "    df_featured = df_featured.withColumn(\"is_bundle\", when(lower(col(\"title\")).rlike(\"bundle|set|pack\"), 1).otherwise(0))\n",
    "\n",
    "df_featured = df_featured.withColumn(\"log_rating_number\", log1p(col(\"rating_number\")))\n",
    "df_featured = df_featured.withColumn(\"log_store_freq\", log1p(col(\"store_freq\")))\n",
    "df_featured = df_featured.withColumn(\"label\", log1p(col(\"price\")))\n",
    "\n",
    "print(f\"Ready for Decision Tree: {df_featured.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b06b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    Tokenizer, HashingTF, IDF, StringIndexer, \n",
    "    VectorAssembler, VectorIndexer\n",
    ")\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "stages = []\n",
    "\n",
    "if \"title\" in df_featured.columns:\n",
    "    tokenizer = Tokenizer(inputCol=\"title\", outputCol=\"words\")\n",
    "    stages.append(tokenizer)\n",
    "    \n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"raw_features\", numFeatures=1000)\n",
    "    stages.append(hashingTF)\n",
    "    \n",
    "    idf = IDF(inputCol=\"raw_features\", outputCol=\"title_features\")\n",
    "    stages.append(idf)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"main_category\", outputCol=\"category_idx\", handleInvalid=\"keep\")\n",
    "stages.append(indexer)\n",
    "\n",
    "numeric_cols = [\"average_rating\", \"log_rating_number\", \"log_store_freq\", \"category_idx\"]\n",
    "optional_cols = [\"title_len\", \"is_premium\", \"is_bundle\", \"features_count\"]\n",
    "\n",
    "for c in optional_cols:\n",
    "    if c in df_featured.columns:\n",
    "        numeric_cols.append(c)\n",
    "\n",
    "input_cols = numeric_cols\n",
    "if \"title\" in df_featured.columns:\n",
    "    input_cols.append(\"title_features\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features_raw\")\n",
    "stages.append(assembler)\n",
    "\n",
    "feature_indexer = VectorIndexer(\n",
    "    inputCol=\"features_raw\", \n",
    "    outputCol=\"features_vector\", \n",
    "    maxCategories=10, \n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "stages.append(feature_indexer)\n",
    "\n",
    "dt = DecisionTreeRegressor(\n",
    "    featuresCol=\"features_vector\", \n",
    "    labelCol=\"label\",\n",
    "    maxDepth=12,          \n",
    "    minInstancesPerNode=2,\n",
    "    maxBins=128,          \n",
    "    seed=42\n",
    ")\n",
    "stages.append(dt)\n",
    "\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89bfbf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df_featured.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Training Decision Tree...\")\n",
    "model = pipeline.fit(train_data)\n",
    "print(\"Done!\")\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "predictions = predictions.withColumn(\"prediction_price\", expm1(col(\"prediction\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e5a5074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R2 (Log Scale): 0.1711\n",
      "  RMSE (Real $):  21.77\n",
      "  MAE (Real $):   14.53\n",
      "+---------------------------------------------+-----+------------------+\n",
      "|title                                        |price|prediction_price  |\n",
      "+---------------------------------------------+-----+------------------+\n",
      "|Warhammer 40k Adeptus Mechanicus Codex       |22.41|15.290051444866316|\n",
      "|IA N64 Mem Asst.                             |10.49|28.579394862120477|\n",
      "|Beetle Adventure Racing                      |43.98|28.579394862120477|\n",
      "|Scubapro Quick Release Mouthpiece Clamp      |14.95|22.632618188801377|\n",
      "|Replacement Lens (Screen) for Game Boy Pocket|12.94|18.178456447566855|\n",
      "+---------------------------------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "r2_eval = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "rmse_eval = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction_price\", metricName=\"rmse\")\n",
    "mae_eval = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction_price\", metricName=\"mae\")\n",
    "\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"  R2 (Log Scale): {r2_eval.evaluate(predictions):.4f}\")\n",
    "print(f\"  RMSE (Real $):  {rmse_eval.evaluate(predictions):.2f}\")\n",
    "print(f\"  MAE (Real $):   {mae_eval.evaluate(predictions):.2f}\")\n",
    "\n",
    "predictions.select(\"title\", \"price\", \"prediction_price\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dd54df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned regression tree depth: 12\n",
      "Num nodes: 3291\n",
      "\n",
      "Tree Structure (Top levels):\n",
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_b64a5d93f8e1, depth=12, numNodes=3291, numFeatures=1008\n",
      "  If (feature 174 in {1.0,2.0,3.0,4.0,5.0,6.0,7.0})\n",
      "   If (feature 3 in {3.0,5.0,11.0,15.0,16.0,29.0})\n",
      "    If (feature 3 in {5.0,16.0})\n",
      "     If (feature 2 <= 2.8029010331479984)\n",
      "      If (feature 489 in {0.0})\n",
      "       If (feature 388 in {0.0})\n",
      "        If (feature 4 <= 133.5)\n",
      "         If (feature 482 in {0.0})\n",
      "          If (feature 910 in {0.0})\n",
      "           If (feature 741 in {0.0})\n",
      "            If (feature 162 in {0.0})\n",
      "             If (feature 888 in {0.0})\n",
      "              Predict: 2.0362640180706943\n",
      "             Else (feature 888 not in {0.0})\n",
      "              Predict: 3.5051302991935245\n",
      "            Else (feature 162 not in {0.0})\n",
      "             Predict: 3.2638956279612708\n",
      "           Else (feature 741 not in {0.0})\n",
      "            If (feature 71 in {1.0})\n",
      "             Predict: 2.0702966732627304\n",
      "            Else (feature 71 not in {1.0})\n",
      "             Predict: 4.136657305264404\n",
      "          E\n"
     ]
    }
   ],
   "source": [
    "dt_model = model.stages[-1]\n",
    "print(f\"Learned regression tree depth: {dt_model.depth}\")\n",
    "print(f\"Num nodes: {dt_model.numNodes}\")\n",
    "print(\"\\nTree Structure (Top levels):\")\n",
    "print(dt_model.toDebugString[:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "056c70de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../../models/regression/dt_price_log_v1\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../../models/regression/dt_price_log_v1\"\n",
    "model.write().overwrite().save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
