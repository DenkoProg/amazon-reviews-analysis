{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c544c4f",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca03b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/denys.koval/Labs/projects/amazon-reviews-analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(Path.cwd(), indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "ROOT_DIR = Path(os.environ.get(\"PROJECT_ROOT\", Path.cwd()))\n",
    "print(f\"Project root: {ROOT_DIR}\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092250d1",
   "metadata": {},
   "source": [
    "## 2. Initialize Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/02 23:22:04 WARN Utils: Your hostname, LT-W-7826.local, resolves to a loopback address: 127.0.0.1; using 192.168.31.164 instead (on interface en0)\n",
      "25/12/02 23:22:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/02 23:22:04 WARN Utils: Your hostname, LT-W-7826.local, resolves to a loopback address: 127.0.0.1; using 192.168.31.164 instead (on interface en0)\n",
      "25/12/02 23:22:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/02 23:22:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/02 23:22:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Spark Session created successfully!\n",
      "Spark Version: 4.0.1\n",
      "Spark App Name: AmazonReviews\n",
      "Spark Master: local[*]\n",
      "Spark UI: http://192.168.31.164:4040\n"
     ]
    }
   ],
   "source": [
    "from src.amazon_reviews_analysis.utils import build_spark\n",
    "\n",
    "spark = build_spark()\n",
    "\n",
    "print(\"âœ“ Spark Session created successfully!\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark App Name: {spark.sparkContext.appName}\")\n",
    "print(f\"Spark Master: {spark.sparkContext.master}\")\n",
    "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e17531",
   "metadata": {},
   "source": [
    "## 3. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49279ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data already extracted\n",
      "\n",
      "Data location: /Users/denys.koval/Labs/projects/amazon-reviews-analysis/data/classification/extracted\n"
     ]
    }
   ],
   "source": [
    "DATA_ZIP = ROOT_DIR / \"data/classification/classification_reviews.zip\"\n",
    "EXTRACT_DIR = ROOT_DIR / \"data/classification/extracted\"\n",
    "\n",
    "if not EXTRACT_DIR.exists():\n",
    "    print(f\"ðŸ“¦ Extracting {DATA_ZIP}...\")\n",
    "    with zipfile.ZipFile(DATA_ZIP, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    print(\"âœ“ Extraction complete!\")\n",
    "else:\n",
    "    print(\"âœ“ Data already extracted\")\n",
    "\n",
    "print(f\"\\nData location: {EXTRACT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dab569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 35,202,489\n",
      "\n",
      "Columns: ['rating', 'title', 'text', 'verified_purchase', 'parent_asin', 'category_label', 'label']\n",
      "root\n",
      " |-- rating: double (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- verified_purchase: boolean (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- category_label: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(str(EXTRACT_DIR))\n",
    "\n",
    "print(f\"Total records: {df.count():,}\")\n",
    "print(f\"\\nColumns: {df.columns}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8697e146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------+--------------------------------------------------+-----------------+-----------+--------------+-----+\n",
      "|rating|                          title|                                              text|verified_purchase|parent_asin|category_label|label|\n",
      "+------+-------------------------------+--------------------------------------------------+-----------------+-----------+--------------+-----+\n",
      "|   5.0|  Perfect for my granddaughters|               Just what my granddaughters wanted.|             true| B0771XZ99Y|        sports|    2|\n",
      "|   3.0|             Pretty but Fragile|It makes an amusing popping sound but I thought...|             true| B0814BFFJH|        sports|    1|\n",
      "|   5.0|                    Love these!|I had been searching for a while for some comfo...|             true| B08DXCXYK9|        sports|    2|\n",
      "|   5.0|                     Five Stars|           They worked just as described. Thanks !|             true| B002QG1WJY|        sports|    2|\n",
      "|   1.0|It does not work as advertised.|Don't waste your money. Very poor quality and i...|            false| B00PB78RT8|        sports|    0|\n",
      "+------+-------------------------------+--------------------------------------------------+-----------------+-----------+--------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e524280",
   "metadata": {},
   "source": [
    "## 4. Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19211038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==========>                                             (12 + 12) / 62]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|label|   count|\n",
      "+-----+--------+\n",
      "|    0| 5372399|\n",
      "|    1| 2451737|\n",
      "|    2|27378353|\n",
      "+-----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check target distribution (label: 0=negative, 1=neutral, 2=positive)\n",
    "df.groupBy(\"label\").count().orderBy(\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a51c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=======================================================> (60 + 2) / 62]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|text|label|\n",
      "+----+-----+\n",
      "|   0|    0|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "TARGET_COL = \"label\"  # 0=negative, 1=neutral, 2=positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045b263",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe31d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset: 35,202,489 records\n",
      "\n",
      "Label distribution (0=negative, 1=positive, 2=neutral):\n",
      "+-----+--------+\n",
      "|label|   count|\n",
      "+-----+--------+\n",
      "|  0.0| 5372399|\n",
      "|  1.0| 2451737|\n",
      "|  2.0|27378353|\n",
      "+-----+--------+\n",
      "\n",
      "+-----+--------+\n",
      "|label|   count|\n",
      "+-----+--------+\n",
      "|  0.0| 5372399|\n",
      "|  1.0| 2451737|\n",
      "|  2.0|27378353|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Label is already 0, 1, 2 - just cast to double for MLlib\n",
    "df_clean = df.withColumn(\"label\", col(TARGET_COL).cast(\"double\"))\n",
    "\n",
    "print(f\"Clean dataset: {df_clean.count():,} records\")\n",
    "print(\"\\nLabel distribution (0=negative, 1=neutral, 2=positive):\")\n",
    "df_clean.groupBy(\"label\").count().orderBy(\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "075b06a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 28,158,683 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=======================================================>(61 + 1) / 62]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 7,043,806 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "train_df, test_df = df_clean.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training set: {train_df.count():,} records\")\n",
    "print(f\"Test set: {test_df.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d5078",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Feature transformers defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/02 23:23:05 WARN StopWordsRemover: Default locale set was [en_UA]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=TEXT_COL, outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "print(\"âœ“ Feature transformers defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedbd669",
   "metadata": {},
   "source": [
    "## 7. Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Pipeline defined\n",
      "Stages: ['Tokenizer', 'StopWordsRemover', 'HashingTF', 'IDF', 'LogisticRegression']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100, regParam=0.01)\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashing_tf, idf, lr])\n",
    "\n",
    "print(f\"Stages: {[stage.__class__.__name__ for stage in pipeline.getStages()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c570198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/02 23:35:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/12/02 23:35:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Training model...\")\n",
    "model = pipeline.fit(train_df)\n",
    "print(\"âœ“ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d32fa7",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723b005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-----+----------+--------------------------------------------------+\n",
      "|                                              text|label|prediction|                                       probability|\n",
      "+--------------------------------------------------+-----+----------+--------------------------------------------------+\n",
      "|DO NOT BUY!!!! I thought I was buying just a se...|  0.0|       0.0|[0.7779339377289416,0.09088079519457837,0.13118...|\n",
      "|Not quite two years since purchasing this tread...|  0.0|       0.0|[0.9300297060449276,0.03207961970025403,0.03789...|\n",
      "|Product did not preform as advertised.<br />The...|  0.0|       2.0|[0.1691622521435565,0.10854435878478087,0.72229...|\n",
      "|Ordered this DONUT BEACH TOWEL..... Received a ...|  0.0|       0.0|[0.9756340349218156,0.015514565947463744,0.0088...|\n",
      "|I dislike that socks are expensive and there is...|  0.0|       0.0|[0.707144940457979,0.10893299883598173,0.183922...|\n",
      "|Horrible!  Somehow, their definition of &#34;as...|  0.0|       0.0|[0.8839928126697755,0.04129870996958493,0.07470...|\n",
      "|We recently went on a two-week vacation camping...|  0.0|       0.0|[0.9947417655584319,0.005257373022413879,8.6141...|\n",
      "|Had to review it low. Box showed up, after very...|  0.0|       0.0|[0.88699384841311,0.07446134815896444,0.0385448...|\n",
      "|                      $17 over MSRP?!!! Seriously?|  0.0|       2.0|[0.25269049684034867,0.09866718548893548,0.6486...|\n",
      "|When you pay over $20 for a very simple 3\" clea...|  0.0|       2.0|[0.20355424345335937,0.21522690408053155,0.5812...|\n",
      "+--------------------------------------------------+-----+----------+--------------------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "\n",
    "predictions.select(TEXT_COL, \"label\", \"prediction\", \"probability\").show(10, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0c4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 154:======================================================>(61 + 1) / 62]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "Accuracy:           0.8461\n",
      "F1 Score:           0.8158\n",
      "Weighted Precision: 0.8119\n",
      "Weighted Recall:    0.8461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "evaluator_precision = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "precision = evaluator_precision.evaluate(predictions)\n",
    "\n",
    "evaluator_recall = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "recall = evaluator_recall.evaluate(predictions)\n",
    "\n",
    "print(\"RESULTS\")\n",
    "print(f\"Accuracy:           {accuracy:.4f}\")\n",
    "print(f\"F1 Score:           {f1:.4f}\")\n",
    "print(f\"Weighted Precision: {precision:.4f}\")\n",
    "print(f\"Weighted Recall:    {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a909126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 156:======================================================>(61 + 1) / 62]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-------+\n",
      "|label|prediction|  count|\n",
      "+-----+----------+-------+\n",
      "|  0.0|       0.0| 589687|\n",
      "|  0.0|       1.0|  15482|\n",
      "|  0.0|       2.0| 470709|\n",
      "|  1.0|       0.0| 104550|\n",
      "|  1.0|       1.0|  25901|\n",
      "|  1.0|       2.0| 360443|\n",
      "|  2.0|       0.0| 105373|\n",
      "|  2.0|       1.0|  27266|\n",
      "|  2.0|       2.0|5344395|\n",
      "+-----+----------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "confusion_matrix = predictions.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad3e5c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 159:======================================================>(61 + 1) / 62]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+-------------------+\n",
      "|label|  total|correct|           accuracy|\n",
      "+-----+-------+-------+-------------------+\n",
      "|  0.0|1075878| 589687|  0.548098390337938|\n",
      "|  1.0| 490894|  25901|0.05276291826748748|\n",
      "|  2.0|5477034|5344395| 0.9757826955246215|\n",
      "+-----+-------+-------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as spark_sum, when\n",
    "\n",
    "per_class = predictions.groupBy(\"label\").agg(\n",
    "    count(\"*\").alias(\"total\"), spark_sum(when(col(\"label\") == col(\"prediction\"), 1).otherwise(0)).alias(\"correct\")\n",
    ")\n",
    "per_class = per_class.withColumn(\"accuracy\", col(\"correct\") / col(\"total\"))\n",
    "per_class.orderBy(\"label\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ed742",
   "metadata": {},
   "source": [
    "## 9. Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95be36ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model saved to /Users/denys.koval/Labs/projects/amazon-reviews-analysis/models/spark_lr_classifier\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = ROOT_DIR / \"models\" / \"spark_lr_classifier\"\n",
    "\n",
    "model.write().overwrite().save(str(MODEL_DIR))\n",
    "\n",
    "print(f\"âœ“ Model saved to {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03a8e5",
   "metadata": {},
   "source": [
    "## 10. Quick Inference Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd0ccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/02 23:58:04 WARN StopWordsRemover: Default locale set was [en_UA]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n",
      "25/12/02 23:58:05 WARN StopWordsRemover: Default locale set was [en_UA]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n",
      "25/12/02 23:58:05 WARN StopWordsRemover: Default locale set was [en_UA]; however, it was not found in available locales in JVM, falling back to en_US locale. Set param `locale` in order to respect another locale.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+----------+\n",
      "|                                                  text|prediction|\n",
      "+------------------------------------------------------+----------+\n",
      "|This product is amazing! Best purchase I've ever made.|       2.0|\n",
      "|     Terrible quality, broke after one day. Don't buy!|       0.0|\n",
      "|          It's okay, nothing special but does the job.|       2.0|\n",
      "+------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "loaded_model = PipelineModel.load(str(MODEL_DIR))\n",
    "\n",
    "sample_data = spark.createDataFrame(\n",
    "    [\n",
    "        (\"This product is amazing! Best purchase I've ever made.\",),\n",
    "        (\"Terrible quality, broke after one day. Don't buy!\",),\n",
    "        (\"It's okay, nothing special but does the job.\",),\n",
    "    ],\n",
    "    [TEXT_COL],\n",
    ")\n",
    "\n",
    "sample_predictions = loaded_model.transform(sample_data)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "sample_predictions.select(TEXT_COL, \"prediction\").show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b891a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon-reviews-analysis (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
