{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5be2e918",
   "metadata": {},
   "source": [
    "# Video Games Category - EDA\n",
    "\n",
    "**Category**: Video Games\n",
    "\n",
    "**Team Member**: Yaiechnyk Oleh"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0) Setup",
   "id": "2db916113a4b094b"
  },
  {
   "cell_type": "code",
   "id": "63e9cad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T23:59:33.212282Z",
     "start_time": "2025-11-10T23:59:24.871049Z"
    }
   },
   "source": [
    "import os\n",
    "from pyspark.sql import functions as F, Window\n",
    "from amazon_reviews_analysis.utils import build_spark\n",
    "\n",
    "spark = build_spark()\n",
    "print(\"Spark version:\", spark.version)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.15\" 2025-04-15\n",
      "OpenJDK Runtime Environment Temurin-17.0.15+6 (build 17.0.15+6)\n",
      "OpenJDK 64-Bit Server VM Temurin-17.0.15+6 (build 17.0.15+6, mixed mode, sharing)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/11 01:59:27 WARN Utils: Your hostname, MacBook-Pro-Oleh.local, resolves to a loopback address: 127.0.0.1; using 192.168.31.157 instead (on interface en0)\n",
      "25/11/11 01:59:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/11 01:59:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "0017f2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T23:59:49.325332Z",
     "start_time": "2025-11-10T23:59:33.252864Z"
    }
   },
   "source": [
    "RAW_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../../data/raw\"))\n",
    "META_PATH = os.path.join(RAW_DIR, \"meta_categories\",  \"meta_Video_Games.jsonl\")\n",
    "REV_PATH  = os.path.join(RAW_DIR, \"review_categories\", \"Video_Games.jsonl\")\n",
    "\n",
    "print(\"Meta path exists:\", os.path.exists(META_PATH), META_PATH)\n",
    "print(\"Rev  path exists:\", os.path.exists(REV_PATH),  REV_PATH)\n",
    "\n",
    "meta_raw = spark.read.json(META_PATH)\n",
    "rev_raw  = spark.read.json(REV_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta path exists: True /Users/olehyaiechnyk/PycharmProjects/amazon-reviews-analysis/data/raw/meta_categories/meta_Video_Games.jsonl\n",
      "Rev  path exists: True /Users/olehyaiechnyk/PycharmProjects/amazon-reviews-analysis/data/raw/review_categories/Video_Games.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "e98c01ae",
   "metadata": {},
   "source": [
    "## 1) Data Health — nulls & empties"
   ]
  },
  {
   "cell_type": "code",
   "id": "8cf09ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T00:00:40.896541Z",
     "start_time": "2025-11-10T23:59:49.588721Z"
    }
   },
   "source": [
    "\n",
    "def null_report(df, name):\n",
    "    total = df.count()\n",
    "    rows = []\n",
    "    for c in df.columns:\n",
    "        n = df.where(F.col(c).isNull()).count()\n",
    "        rows.append((c, n, n/total if total else 0.0))\n",
    "    out = spark.createDataFrame(rows, [\"column\",\"null_count\",\"null_rate\"])\n",
    "    print(f\"--- Nulls in {name} (total {total}) ---\")\n",
    "    out.orderBy(F.desc(\"null_rate\")).show(50, truncate=False)\n",
    "    return out\n",
    "\n",
    "meta_nulls = null_report(meta_raw, \"metadata\")\n",
    "rev_nulls  = null_report(rev_raw, \"reviews\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/11 01:59:49 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Nulls in metadata (total 137269) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------------------+\n",
      "|column         |null_count|null_rate           |\n",
      "+---------------+----------+--------------------+\n",
      "|bought_together|137269    |1.0                 |\n",
      "|author         |137007    |0.998091338903904   |\n",
      "|subtitle       |136919    |0.9974502618945282  |\n",
      "|price          |75261     |0.5482738273025957  |\n",
      "|main_category  |11035     |0.08038959998251609 |\n",
      "|store          |4361      |0.031769736794177855|\n",
      "|title          |0         |0.0                 |\n",
      "|rating_number  |0         |0.0                 |\n",
      "|videos         |0         |0.0                 |\n",
      "|average_rating |0         |0.0                 |\n",
      "|description    |0         |0.0                 |\n",
      "|features       |0         |0.0                 |\n",
      "|details        |0         |0.0                 |\n",
      "|categories     |0         |0.0                 |\n",
      "|images         |0         |0.0                 |\n",
      "|parent_asin    |0         |0.0                 |\n",
      "+---------------+----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:============================================>           (16 + 4) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Nulls in reviews (total 4624615) ---\n",
      "+-----------------+----------+---------+\n",
      "|column           |null_count|null_rate|\n",
      "+-----------------+----------+---------+\n",
      "|timestamp        |0         |0.0      |\n",
      "|images           |0         |0.0      |\n",
      "|helpful_vote     |0         |0.0      |\n",
      "|user_id          |0         |0.0      |\n",
      "|text             |0         |0.0      |\n",
      "|verified_purchase|0         |0.0      |\n",
      "|title            |0         |0.0      |\n",
      "|parent_asin      |0         |0.0      |\n",
      "|asin             |0         |0.0      |\n",
      "|rating           |0         |0.0      |\n",
      "+-----------------+----------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Metadata (137,269 products): Shows significant missing data. bought_together (100%), author (99.8%), and subtitle (99.7%) are almost entirely null. Crucially, price is null for 54.8% of products.\n",
    "\n",
    "Reviews (4,624,615 reviews): The dataset is perfectly clean in terms of nulls. All columns report 0 nulls and a 0.0 null rate."
   ],
   "id": "25b9b5aee403219d"
  },
  {
   "cell_type": "code",
   "id": "889005ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T00:00:42.362577Z",
     "start_time": "2025-11-11T00:00:40.954770Z"
    }
   },
   "source": [
    "array_like_cols = [c for c, t in meta_raw.dtypes if t.startswith(\"array\") or t.startswith(\"map\")]\n",
    "\n",
    "def empty_rate_expr(colname):\n",
    "    return F.avg(F.when(F.col(colname).isNull() | (F.size(F.col(colname)) == 0), 1).otherwise(0)).alias(colname)\n",
    "\n",
    "if array_like_cols:\n",
    "    empties = meta_raw.select([empty_rate_expr(c) for c in array_like_cols]).collect()[0].asDict()\n",
    "    print(\"--- Empty rate (metadata array/map-like) ---\")\n",
    "    for k, v in empties.items():\n",
    "        print(f\"{k}: {float(v):.4f}\")\n",
    "else:\n",
    "    print(\"No array/map fields detected.\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 88:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Empty rate (metadata array/map-like) ---\n",
      "categories: 0.0921\n",
      "description: 0.3769\n",
      "features: 0.2877\n",
      "images: 0.0010\n",
      "videos: 0.7894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The output shows that videos are empty 78.9% of the time, description is empty 37.7%, and features is empty 28.8%. This indicates that while not \"null,\" these fields often lack data.",
   "id": "b9a8b6f12e189107"
  },
  {
   "cell_type": "markdown",
   "id": "5720fe10",
   "metadata": {},
   "source": [
    "## 2) Deduplicate & trim reviews"
   ]
  },
  {
   "cell_type": "code",
   "id": "db358cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T00:02:06.350306Z",
     "start_time": "2025-11-11T00:00:42.397915Z"
    }
   },
   "source": [
    "dup_keys = [\"user_id\",\"asin\",\"timestamp\"]\n",
    "rev_counts_before = rev_raw.count()\n",
    "rev_dups = (rev_raw.groupBy([F.col(c) for c in dup_keys]).count().filter(\"count > 1\"))\n",
    "print(\"Duplicate groups:\", rev_dups.count())\n",
    "\n",
    "w = Window.partitionBy(*dup_keys).orderBy(F.lit(1))\n",
    "rev_dedup = rev_raw.withColumn(\"rn\", F.row_number().over(w)).where(\"rn = 1\").drop(\"rn\")\n",
    "print(\"After dedup:\", rev_dedup.count())\n",
    "\n",
    "# Remove empty/whitespace-only text\n",
    "rev_clean = rev_dedup.where(F.length(F.trim(F.col(\"text\"))) > 0)\n",
    "print(\"Removed empty texts:\", rev_dedup.count() - rev_clean.count())\n",
    "print(\"Final reviews:\", rev_clean.count())\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate groups: 45196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dedup: 4570967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty texts: 3564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 120:============================================>          (16 + 4) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final reviews: 4567403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This step removes 3,564 empty-text reviews, resulting in a final, clean review dataset (rev_clean) containing 4,567,403 reviews.",
   "id": "20198747811ee27c"
  },
  {
   "cell_type": "markdown",
   "id": "0546d41d",
   "metadata": {},
   "source": "## 3) Price cleaning"
  },
  {
   "cell_type": "code",
   "id": "34f8b0fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T00:02:09.305513Z",
     "start_time": "2025-11-11T00:02:06.785581Z"
    }
   },
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "num_pat = r'([0-9]{1,3}(?:,[0-9]{3})*(?:\\.[0-9]+)?|[0-9]+(?:\\.[0-9]+)?)'\n",
    "\n",
    "meta_price = (\n",
    "    meta_raw\n",
    "      .withColumn(\"price_raw\", F.col(\"price\").cast(\"string\"))\n",
    "      .withColumn(\"price_num_str\", F.regexp_extract(F.col(\"price_raw\"), num_pat, 1))\n",
    "      .withColumn(\n",
    "          \"price_num_str\",\n",
    "          F.when(F.length(\"price_num_str\") == 0, F.lit(None))\n",
    "           .otherwise(F.regexp_replace(F.col(\"price_num_str\"), \",\", \"\"))\n",
    "      )\n",
    "      .withColumn(\"clean_price\", F.col(\"price_num_str\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "total_products  = meta_price.count()\n",
    "nonnull_prices  = meta_price.filter(F.col(\"clean_price\").isNotNull()).count()\n",
    "print(f\"Price coverage: {nonnull_prices}/{total_products} = {nonnull_prices/total_products:.2%}\")\n",
    "\n",
    "(meta_price\n",
    "  .filter(F.col(\"clean_price\").isNotNull())\n",
    "  .select(\n",
    "      F.mean(\"clean_price\").alias(\"mean_price\"),\n",
    "      F.stddev(\"clean_price\").alias(\"std_price\"),\n",
    "      F.expr(\"percentile(clean_price, array(0.5))\")[0].alias(\"median_price\"),\n",
    "      F.min(\"clean_price\").alias(\"min_price\"),\n",
    "      F.max(\"clean_price\").alias(\"max_price\"),\n",
    "  )\n",
    "  .show(truncate=False)\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price coverage: 61992/137269 = 45.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 130:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+------------+---------+---------+\n",
      "|mean_price     |std_price        |median_price|min_price|max_price|\n",
      "+---------------+-----------------+------------+---------+---------+\n",
      "|44.743041844107|69.55919557995735|24.95       |0.0      |999.99   |\n",
      "+---------------+-----------------+------------+---------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "43cef356",
   "metadata": {},
   "source": "## 4) Platform parsing"
  },
  {
   "cell_type": "code",
   "id": "b0e4b918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T00:02:11.752202Z",
     "start_time": "2025-11-11T00:02:09.378555Z"
    }
   },
   "source": [
    "import re\n",
    "@F.udf(\"string\")\n",
    "def parse_platform(title, categories):\n",
    "    base = \"\"\n",
    "    if title:\n",
    "        base += \" \" + title.lower()\n",
    "    if categories is not None:\n",
    "        try:\n",
    "            if isinstance(categories, list):\n",
    "                base += \" \" + \" \".join([(\" \".join(x) if isinstance(x, list) else str(x)) for x in categories])\n",
    "            else:\n",
    "                base += \" \" + str(categories)\n",
    "        except Exception:\n",
    "            pass\n",
    "    txt = base.lower()\n",
    "    patterns = [\n",
    "        (\"PlayStation 5\", r\"\\bps5\\b|\\bplaystation 5\\b\"),\n",
    "        (\"PlayStation 4\", r\"\\bps4\\b|\\bplaystation 4\\b\"),\n",
    "        (\"PlayStation 3\", r\"\\bps3\\b|\\bplaystation 3\\b\"),\n",
    "        (\"Xbox Series\",   r\"\\bxbox series\\b|\\bxbox series x\\b|\\bxbox series s\\b\"),\n",
    "        (\"Xbox One\",      r\"\\bxbox one\\b\"),\n",
    "        (\"Xbox 360\",      r\"\\bxbox 360\\b\"),\n",
    "        (\"Nintendo Switch\", r\"\\bswitch\\b|\\bnintendo switch\\b\"),\n",
    "        (\"Wii U\",         r\"\\bwii u\\b\"),\n",
    "        (\"Wii\",           r\"\\bwii\\b\"),\n",
    "        (\"3DS/DS\",        r\"\\b3ds\\b|\\b2ds\\b|\\bds\\b\"),\n",
    "        (\"PC\",            r\"\\bpc\\b|\\bwindows\\b|\\bsteam\\b|\\bmac\\b\"),\n",
    "    ]\n",
    "    for label, pat in patterns:\n",
    "        if re.search(pat, txt):\n",
    "            return label\n",
    "    return \"Other/Unknown\"\n",
    "\n",
    "meta_clean = (meta_price\n",
    "              .withColumn(\"platform\", parse_platform(F.col(\"title\"), F.col(\"categories\")))\n",
    "             )\n",
    "\n",
    "meta_clean.groupBy(\"platform\").count().orderBy(F.desc(\"count\")).show(50, truncate=False)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 133:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|platform       |count|\n",
      "+---------------+-----+\n",
      "|PC             |35700|\n",
      "|Other/Unknown  |28077|\n",
      "|Nintendo Switch|17323|\n",
      "|PlayStation 4  |14157|\n",
      "|3DS/DS         |8488 |\n",
      "|Xbox One       |7388 |\n",
      "|PlayStation 3  |5820 |\n",
      "|Xbox 360       |5683 |\n",
      "|PlayStation 5  |5301 |\n",
      "|Wii            |5292 |\n",
      "|Wii U          |2132 |\n",
      "|Xbox Series    |1908 |\n",
      "+---------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The table shows us the distribution of the 137,269 products by the newly parsed platform. PC is the most common (35,700), followed by Nintendo Switch (17,323) and PlayStation 4 (14,157).",
   "id": "613144d239e2835d"
  },
  {
   "cell_type": "markdown",
   "id": "c353baff",
   "metadata": {},
   "source": "## 5) Linkage check"
  },
  {
   "cell_type": "code",
   "id": "1740b40e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T00:03:02.971363Z",
     "start_time": "2025-11-11T00:02:11.824757Z"
    }
   },
   "source": [
    "\n",
    "rev_pa = rev_clean.select(\"parent_asin\").distinct().withColumnRenamed(\"parent_asin\",\"pa_r\")\n",
    "meta_pa = meta_clean.select(\"parent_asin\").distinct().withColumnRenamed(\"parent_asin\",\"pa_m\")\n",
    "\n",
    "missing = rev_pa.join(meta_pa, rev_pa.pa_r == meta_pa.pa_m, \"left_anti\").count()\n",
    "print(\"review parent_asin missing in metadata:\", missing)\n",
    "print(\"distinct parent_asin in reviews:\", rev_pa.count())\n",
    "print(\"distinct parent_asin in metadata:\", meta_pa.count())\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review parent_asin missing in metadata: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct parent_asin in reviews: 137196\n",
      "distinct parent_asin in metadata: 137269\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "0359d9a8",
   "metadata": {},
   "source": "## 6) Сleaned datasets"
  },
  {
   "cell_type": "code",
   "id": "9daa901f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T00:03:41.988032Z",
     "start_time": "2025-11-11T00:03:03.097583Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJ_ROOT = Path.cwd().parents[1]\n",
    "OUT_DIR = PROJ_ROOT / \"data\" / \"raw\" / \"review_categories\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REV_OUT = OUT_DIR / \"reviews_clean.parquet\"\n",
    "META_OUT = OUT_DIR / \"metadata_clean.parquet\"\n",
    "\n",
    "rev_clean.write.mode(\"overwrite\").parquet(str(REV_OUT))\n",
    "meta_clean.write.mode(\"overwrite\").parquet(str(META_OUT))\n",
    "\n",
    "\n",
    "print(\"✓ Saved:\")\n",
    "print(\" -\", REV_OUT)\n",
    "print(\" -\", META_OUT)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 163:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved:\n",
      " - /Users/olehyaiechnyk/PycharmProjects/amazon-reviews-analysis/data/raw/review_categories/reviews_clean.parquet\n",
      " - /Users/olehyaiechnyk/PycharmProjects/amazon-reviews-analysis/data/raw/review_categories/metadata_clean.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "amazon-reviews-analysis",
   "language": "python",
   "display_name": "amazon-reviews-analysis"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
