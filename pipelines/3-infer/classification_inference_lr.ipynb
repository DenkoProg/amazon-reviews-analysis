{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedfa161",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(Path.cwd(), indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "ROOT_DIR = Path(os.environ.get(\"PROJECT_ROOT\", Path.cwd()))\n",
    "print(f\"Project root: {ROOT_DIR}\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4eaea",
   "metadata": {},
   "source": [
    "## 2. Initialize Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20934431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.amazon_reviews_analysis.utils import build_spark\n",
    "\n",
    "spark = build_spark()\n",
    "\n",
    "print(\"✓ Spark Session created successfully!\")\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801c719",
   "metadata": {},
   "source": [
    "## 3. Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "MODEL_DIR = ROOT_DIR / \"models\" / \"spark_lr_classifier\"\n",
    "TEXT_COL = \"text\"\n",
    "\n",
    "model = PipelineModel.load(str(MODEL_DIR))\n",
    "\n",
    "print(f\"✓ Model loaded from {MODEL_DIR}\")\n",
    "print(f\"Pipeline stages: {[stage.__class__.__name__ for stage in model.stages]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f798067",
   "metadata": {},
   "source": [
    "## 4. Define Label Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07771927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "LABEL_MAP = {0.0: \"negative\", 1.0: \"positive\", 2.0: \"neutral\"}\n",
    "\n",
    "\n",
    "@udf(StringType())\n",
    "def label_to_sentiment(prediction):\n",
    "    return LABEL_MAP.get(prediction, \"unknown\")\n",
    "\n",
    "\n",
    "print(\"Label mapping:\")\n",
    "for k, v in LABEL_MAP.items():\n",
    "    print(f\"  {int(k)} -> {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0db2f",
   "metadata": {},
   "source": [
    "## 5. Inference on Custom Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37927b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_reviews = [\n",
    "    \"This product is absolutely amazing! Best purchase I've ever made. Highly recommend!\",\n",
    "    \"Terrible quality. Broke after just one day of use. Complete waste of money.\",\n",
    "    \"It's okay, nothing special. Does the job but nothing more.\",\n",
    "    \"I love this! Works perfectly and arrived quickly. Five stars!\",\n",
    "    \"Not worth the price. Very disappointed with the quality.\",\n",
    "    \"Average product. Some good features, some bad. Neutral overall.\",\n",
    "    \"Exceeded my expectations! Will definitely buy again.\",\n",
    "    \"Awful experience. Product was damaged and customer service was unhelpful.\",\n",
    "    \"Decent for the price. Gets the job done.\",\n",
    "    \"Perfect gift for my friend. She absolutely loved it!\",\n",
    "]\n",
    "\n",
    "input_df = spark.createDataFrame([(review,) for review in custom_reviews], [TEXT_COL])\n",
    "\n",
    "print(f\"Loaded {input_df.count()} custom reviews for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(input_df)\n",
    "\n",
    "results = predictions.withColumn(\"sentiment\", label_to_sentiment(col(\"prediction\")))\n",
    "\n",
    "print(\"Inference Results:\")\n",
    "print(\"=\" * 80)\n",
    "results.select(TEXT_COL, \"prediction\", \"sentiment\").show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4cbe4",
   "metadata": {},
   "source": [
    "## 6. Detailed Results with Probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a26df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import element_at\n",
    "\n",
    "detailed_results = results.select(\n",
    "    TEXT_COL,\n",
    "    \"sentiment\",\n",
    "    element_at(col(\"probability\"), 1).alias(\"prob_negative\"),\n",
    "    element_at(col(\"probability\"), 2).alias(\"prob_positive\"),\n",
    "    element_at(col(\"probability\"), 3).alias(\"prob_neutral\"),\n",
    ")\n",
    "\n",
    "print(\"Detailed Results with Class Probabilities:\")\n",
    "detailed_results.show(truncate=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acefa09",
   "metadata": {},
   "source": [
    "## 8. Interactive Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review_text: str) -> dict:\n",
    "    \"\"\"Predict sentiment for a single review.\"\"\"\n",
    "    input_df = spark.createDataFrame([(review_text,)], [TEXT_COL])\n",
    "    prediction = model.transform(input_df).collect()[0]\n",
    "\n",
    "    probs = prediction[\"probability\"]\n",
    "    pred_label = int(prediction[\"prediction\"])\n",
    "\n",
    "    return {\n",
    "        \"text\": review_text,\n",
    "        \"sentiment\": LABEL_MAP[float(pred_label)],\n",
    "        \"confidence\": float(probs[pred_label]),\n",
    "        \"probabilities\": {\"negative\": float(probs[0]), \"positive\": float(probs[1]), \"neutral\": float(probs[2])},\n",
    "    }\n",
    "\n",
    "\n",
    "test_review = \"This is the best product I have ever bought!\"\n",
    "result = predict_sentiment(test_review)\n",
    "\n",
    "print(f\"Review: {result['text']}\")\n",
    "print(f\"Sentiment: {result['sentiment']} (confidence: {result['confidence']:.2%})\")\n",
    "print(f\"Probabilities: {result['probabilities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print(\"✓ Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
